<!DOCTYPE html>
<html lang="zh-CN">

<head>
  <meta name="generator" content="Hexo 6.3.0">
  <meta charset="utf-8">
  

  <meta http-equiv="x-dns-prefetch-control" content="on">
  <link rel="dns-prefetch" href="https://fastly.jsdelivr.net">
  <link rel="preconnect" href="https://fastly.jsdelivr.net" crossorigin>
  <link rel="dns-prefetch" href="//unpkg.com">

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  <title>重新定义跨模态生成的流匹配范式，VAFlow让视频「自己发声」 - RSSBOX</title>

  
    <meta name="description" content="本文第一作者是中国人民大学高瓴人工智能学院 2021 级博士生王希华（导师宋睿华），他的主要研究兴趣方向是多模态生成。本文通讯作者是宋睿华长聘副教授，她的 AIMind 团队主要研究方向是多模态感知、交互与生成。背景：从「噪声到声音」到「视频到声音」在多模态生成领域，由视频生成音频（Video-to-Audio，V2A）的任务要求模型理解视频语义，还要在时间维度上精准对齐声音与动态。早期的 V2">
<meta property="og:type" content="article">
<meta property="og:title" content="重新定义跨模态生成的流匹配范式，VAFlow让视频「自己发声」">
<meta property="og:url" content="https://rssbox.mhuig.top/rss/e7f64a91.html">
<meta property="og:site_name" content="RSSBOX">
<meta property="og:description" content="本文第一作者是中国人民大学高瓴人工智能学院 2021 级博士生王希华（导师宋睿华），他的主要研究兴趣方向是多模态生成。本文通讯作者是宋睿华长聘副教授，她的 AIMind 团队主要研究方向是多模态感知、交互与生成。背景：从「噪声到声音」到「视频到声音」在多模态生成领域，由视频生成音频（Video-to-Audio，V2A）的任务要求模型理解视频语义，还要在时间维度上精准对齐声音与动态。早期的 V2">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-b8803d9ec302a4a8077f238d25cc4b4c_720w.jpg?source=d16d100b">
<meta property="og:image" content="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://picx.zhimg.com/v2-054a1c52a00913bb677cee81c0557a06_720w.jpg?source=d16d100b">
<meta property="og:image" content="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-bc89fe97bfa89a6a35c02601f068b5fd_720w.jpg?source=d16d100b">
<meta property="og:image" content="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://picx.zhimg.com/v2-2b21bf90ce94421cd20d221fe6ba501b_720w.jpg?source=d16d100b">
<meta property="og:image" content="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-860b705a8a7df3c4f632a737c3487f01_720w.jpg?source=d16d100b">
<meta property="og:image" content="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-fd1a7426fdc4786fe3b246dd7b0d8b07_720w.jpg?source=d16d100b">
<meta property="og:image" content="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-57c34fe27745da4b511c770d9b418b6f_720w.jpg?source=d16d100b">
<meta property="og:image" content="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://picx.zhimg.com/v2-87b867d241923f72d4b5dc383709b89e_720w.jpg?source=d16d100b">
<meta property="og:image" content="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pica.zhimg.com/v2-f470e95b46b932ec963f0e334d241b25_720w.jpg?source=d16d100b">
<meta property="og:image" content="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-05f253348b1bfaba9c6a21e6f4562fe6_720w.jpg?source=d16d100b">
<meta property="og:image" content="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-b5a0629a6548eef885156b3601a71524_720w.jpg?source=d16d100b">
<meta property="article:published_time" content="2025-10-31T07:29:57.000Z">
<meta property="article:modified_time" content="2025-10-31T07:29:57.000Z">
<meta property="article:author" content="MHuiG">
<meta property="article:tag" content="知乎">
<meta property="article:tag" content="机器之心">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-b8803d9ec302a4a8077f238d25cc4b4c_720w.jpg?source=d16d100b">
  
  

  <!-- feed -->
  
    <link rel="alternate" href="/atom.xml" title="RSSBOX" type="application/atom+xml">
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  

  

  


  
</head>

<body>
  




  <div class="l_body" id="start">
    <aside class="l_left" layout="post">
    


<header class="header">

<div class="logo-wrap"><a class="avatar" target="_blank" rel="noopener" href="https://mhuig.top/"><div class="bg" style="opacity:0;background-image:url(https://static.mhuig.top/gh/cdn-x/placeholder@1.0.2/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="/avatar.png" onerror="javascript:this.classList.add('error');this.src='https://static.mhuig.top/gh/cdn-x/placeholder@1.0.1/image/2659360.svg';"></a><a class="title" href="/"><div class="main">RSSBOX</div><div class="sub normal cap">MHuiGのRSS订阅</div><div class="sub hover cap" style="opacity:0">rssbox.mhuig.top</div></a></div>
<nav class="menu dis-select"><a class="nav-item active" href="/">RSS</a><a class="nav-item" target="_blank" rel="noopener" href="https://blog.mhuig.top/">博客</a><a class="nav-item" target="_blank" rel="noopener" href="https://mhuig.top/">关于</a></nav></header>

<div class="widgets">


<div class="widget-wrap" id="recent"><div class="widget-header cap dis-select"><span class="name">最近更新</span><a class="cap-action" id="rss" title="Subscribe" href="/atom.xml"><svg class="icon" viewbox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="8938"><path d="M800.966 947.251c0-404.522-320.872-732.448-716.69-732.448V62.785c477.972 0 865.44 395.987 865.44 884.466h-148.75z m-162.273 0h-148.74c0-228.98-181.628-414.598-405.678-414.598v-152.01c306.205 0 554.418 253.68 554.418 566.608z m-446.24-221.12c59.748 0 108.189 49.503 108.189 110.557 0 61.063-48.44 110.563-108.188 110.563-59.747 0-108.18-49.5-108.18-110.563 0-61.054 48.433-110.556 108.18-110.556z" p-id="8939"/></svg></a></div><div class="widget-body fs14"><div class="more-item"><a class="title" href="/rss/ee09a392.html">安德尔施帕赫-特普利采岩石林的哥特式拱门, 捷克 (© Kseniya_Milner/Getty Images)</a></div><div class="more-item"><a class="title" href="/rss/ba5ac1e6.html">岚山缤纷的枫叶与竹林, 京都, 日本 (© DoctorEgg/Getty Images)</a></div><div class="more-item"><a class="title" href="/rss/3015d56f.html">布兰城堡入口, 布拉索夫, 罗马尼亚 (© Blue Sky in My pocket/Getty Images)</a></div><div class="more-item"><a class="title" href="/rss/b11a76e.html">杰伊瑟尔梅尔的骆驼, 拉贾斯坦邦, 印度 (© f9photos/Getty Images)</a></div><div class="more-item"><a class="title" href="/rss/1287d9b2.html">法纳尔森林里的古老月桂树，马德拉群岛，葡萄牙 (© Lukas Jonaitis/Shutterstock)</a></div></div></div>



</div>
<footer class="footer dis-select"><div class="social-wrap"><a class="social" href="https://github.com/MHuiG" target="_blank" rel="external nofollow noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://static.mhuig.top/gh/cdn-x/placeholder@1.0.3/social/08a41b181ce68.svg"></a><a class="social" href="https://music.163.com/#/user/home?id=63035382" target="_blank" rel="external nofollow noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://static.mhuig.top/gh/cdn-x/placeholder@1.0.3/social/3845874.svg"></a><a class="social" href="/contact/" rel="noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://static.mhuig.top/gh/cdn-x/placeholder@1.0.3/social/a1b00e20f425d.svg"></a></div></footer>

    </aside>
    <div class="l_main">
      

      


<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/%E7%9F%A5%E4%B9%8E/">知乎</a> <span class="sep"></span> <a class="cap breadcrumb-link" href="/categories/%E7%9F%A5%E4%B9%8E/%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83/">机器之心</a></div><div id="post-meta">发布于&nbsp;<time datetime="2025-10-31T07:29:57.000Z">2025-10-31</time></div></div>

<article class="content md post">
<h1 class="article-title"><span>重新定义跨模态生成的流匹配范式，VAFlow让视频「自己发声」</span></h1>
<div>
<figure data-size="normal"><img class="origin_image zh-lightbox-thumb lazy" data-caption data-original="https://pic1.zhimg.com/v2-b8803d9ec302a4a8077f238d25cc4b4c_720w.jpg?source=d16d100b" data-rawheight="616" data-rawwidth="1080" data-size="normal" referrerpolicy="no-referrer" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-b8803d9ec302a4a8077f238d25cc4b4c_720w.jpg?source=d16d100b" width="1080"></figure><p><br></p><p data-pid="zE7F6BEf"><b>本文第一作者是中国人民大学高瓴人工智能学院 2021 级博士生王希华（导师宋睿华），他的主要研究兴趣方向是多模态生成。本文通讯作者是宋睿华长聘副教授，她的 AIMind 团队主要研究方向是多模态感知、交互与生成。</b></p><p data-pid="OyZ6Q_6f"><b>背景：从「噪声到声音」到「视频到声音」</b></p><p data-pid="aEhqOxG6">在多模态生成领域，由视频生成音频（Video-to-Audio，V2A）的任务要求模型理解视频语义，还要在时间维度上精准对齐声音与动态。早期的 V2A 方法采用自回归（Auto-Regressive）的方式将视频特征作为前缀来逐个生成音频 token，或者以掩码预测（Mask-Prediction）的方式并行地预测音频 token，逐步生成完整音频。</p><p data-pid="fjkQuh-o">这两种方法都依赖于音频的离散化表示，而离散化处理往往由于信息损失会限制音质上限。</p><p data-pid="W5HqvB3-">最近主流方法大多采用扩散模型或流匹配架构，通过「从噪声生成音频」的方式来实现视频驱动的声音合成。这种方式不依赖离散 token 表征，直接在连续的隐空间进行建模。通过采样随机噪声，并将视频信息作为条件，模型从噪声中逐步去噪，最终生成音频。但是这样的范式仍然存在两个天然瓶颈：</p><ol><li data-pid="BZ3vcP2t"><b>同一视频条件下的多对一映射：</b>在训练阶段，模型被训练从不同的采样噪声中预测同一个音频，多对一的映射关系增加了训练难度；推理阶段，由于不同噪声样本通过 ODE 求解得到的推理结果差异较大，生成的音频质量难以保持一致，甚至出现「抽奖」现象。</li><li data-pid="GmlxijMt"><b>不同视频条件下的一对多映射：</b>在训练和推理阶段，模型被要求从相同的采样噪声出发只根据不同视频条件生成不同的音频，这要求模型具备极强的条件处理能力。</li></ol><p><br></p><figure data-size="normal"><img class="origin_image zh-lightbox-thumb lazy" data-caption data-original="https://pica.zhimg.com/v2-054a1c52a00913bb677cee81c0557a06_720w.jpg?source=d16d100b" data-rawheight="324" data-rawwidth="822" data-size="normal" referrerpolicy="no-referrer" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://picx.zhimg.com/v2-054a1c52a00913bb677cee81c0557a06_720w.jpg?source=d16d100b" width="822"></figure><p><br></p><p data-pid="65vm4RYu">主流扩散模型或流匹配架构的挑战</p><p data-pid="ZIzxpD7k">因此，模型需要从随机噪声中逐步「听懂」视频，这一过程依赖复杂的条件机制，导致路径复杂、训练低效且生成结果不稳定。</p><p data-pid="Jxbgd68D">在这一背景下，<b>中国人民大学宋睿华带领的 AIMind 团队与值得买科技 AI 团队</b>提出了一个全新的框架 —— VAFlow。研究者提出：既然从噪声到声音依赖复杂的视频条件机制并且有上述局限，为什么不直接从视频出发生成声音？</p><p data-pid="QsJJZq5f">基于这一思路，<b>团队设计了一个直接建模「视频→音频」映射的跨模态流匹配框架 VAFlow。</b>它摆脱了对高斯噪声先验的依赖，首次实现了<b>从视频分布直接生成音频</b>的范式转变，并在生成质量、语义对齐与同步精度上取得了显著突破。该研究已正式发表于 ICCV 2025。</p><p><br></p><figure data-size="normal"><img class="origin_image zh-lightbox-thumb lazy" data-caption data-original="https://pic1.zhimg.com/v2-bc89fe97bfa89a6a35c02601f068b5fd_720w.jpg?source=d16d100b" data-rawheight="148" data-rawwidth="1060" data-size="normal" referrerpolicy="no-referrer" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-bc89fe97bfa89a6a35c02601f068b5fd_720w.jpg?source=d16d100b" width="1060"></figure><p><br></p><p data-pid="Vfg7QByR">不同生成范式对比</p><p><br></p><figure data-size="normal"><img class="origin_image zh-lightbox-thumb lazy" data-caption data-original="https://picx.zhimg.com/v2-2b21bf90ce94421cd20d221fe6ba501b_720w.jpg?source=d16d100b" data-rawheight="180" data-rawwidth="1012" data-size="normal" referrerpolicy="no-referrer" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://picx.zhimg.com/v2-2b21bf90ce94421cd20d221fe6ba501b_720w.jpg?source=d16d100b" width="1012"></figure><p><br></p><ul><li data-pid="sWy2AznH">论文链接：<a class="external" href="http://link.zhihu.com/?target=https%3A//openaccess.thecvf.com/content/ICCV2025/papers/Wang_VAFlow_Video-to-Audio_Generation_with_Cross-Modality_Flow_Matching_ICCV_2025_paper.pdf" rel="external nofollow noopener noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">openaccess.thecvf.com/c</span><span class="invisible">ontent/ICCV2025/papers/Wang_VAFlow_Video-to-Audio_Generation_with_Cross-Modality_Flow_Matching_ICCV_2025_paper.pdf</span><span class="ellipsis"></span></a></li><li data-pid="QIn0wmsB">主页地址：<a class="external" href="http://link.zhihu.com/?target=https%3A//vaflow.github.io/demo/" rel="external nofollow noopener noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">vaflow.github.io/demo/</span><span class="invisible"></span></a></li></ul><p data-pid="nWGQD_-X"><b>VAFlow：让视频直接「流」向声音</b></p><p data-pid="VQJYqk6o">流匹配（Flow Matching）作为多媒体领域主流的生成算法，它学习一条从起点分布到目标分布的最优传输线路，模型沿着路线一步步把原始分布映射到目标分布。主流的流匹配方法中，模型往往将随机采样的高斯噪声作为起点，以视频为条件输入，逐步将噪声映射到音频分布，这种范式对模型的条件建模能力提出了很大的挑战。而 VAFlow 的核心思想简单又直观：<b>不再从噪声出发，而是直接从视频出发，首次实现了视频分布到音频分布的直接映射。</b></p><p data-pid="plMZVoV1">这意味着模型不再从噪声中解读视频条件「猜测」声音，而是顺着视频的信息流自然生成声音，让视觉与听觉真正合而为一。</p><p><br></p><figure data-size="normal"><img class="origin_image zh-lightbox-thumb lazy" data-caption data-original="https://pic1.zhimg.com/v2-860b705a8a7df3c4f632a737c3487f01_720w.jpg?source=d16d100b" data-rawheight="224" data-rawwidth="1022" data-size="normal" referrerpolicy="no-referrer" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-860b705a8a7df3c4f632a737c3487f01_720w.jpg?source=d16d100b" width="1022"></figure><p><br></p><p data-pid="--Vg2eJo">VAFlow 框架图</p><p data-pid="XznoNxbP">VAFlow 的框架由两个关键模块组成：</p><ul><li data-pid="rJw1wbP2"><b>跨模态对齐自编码器（Alignment VAE）：</b>流匹配模型要求路径两端的分布形状相同，而视频和音频之间的时序和特征维度都存在差异。因此 VAFlow 借助跨模态对齐的变分自编码器调整视频特征以匹配音频特征，解决了视频与音频在时间长度和特征维度上的不匹配问题。</li><li data-pid="DRA0K97D"><b>视频驱动的流匹配生成器（Video-Conditioned Flow Matching Estimator）：</b>VAFlow 采用 Diffusion transformer (DiT) 架构，直接在视频分布与音频分布之间学习最优传输路径，避免了传统噪声先验带来的不稳定效果。</li></ul><p data-pid="vzvUaswJ">除此之外，VAFlow 保留了 DiT 结构中的交叉注意力层，让模型能够在流匹配采样过程中持续融合原始视频特征，同时支持推理过程中的无分类器引导。</p><p data-pid="sg31Ws0k"><b>先验分析：为什么「视频先验」（V-Prior）更优？</b></p><p data-pid="ouP7QATZ">为了验证「以视频为先验」的合理性，团队对比分析了<b>高斯先验 (Gaussian Prior) 与视频先验 (V-Prior)</b> 的表现，从统计特性、可视化结构和生成质量三方面展开实验。</p><p data-pid="SFazlpfj"><b>统计对齐性分析</b></p><p data-pid="6h1Co-OT">研究者计算了先验与音频潜向量之间的 均方误差（MSE） 和 中心核对齐度（CKA），并在有条件（Cond.）与无条件（Uncond.）两种设置下训练模型。结果如下表：</p><p><br></p><figure data-size="normal"><img class="origin_image zh-lightbox-thumb lazy" data-caption data-original="https://picx.zhimg.com/v2-fd1a7426fdc4786fe3b246dd7b0d8b07_720w.jpg?source=d16d100b" data-rawheight="112" data-rawwidth="624" data-size="normal" referrerpolicy="no-referrer" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-fd1a7426fdc4786fe3b246dd7b0d8b07_720w.jpg?source=d16d100b" width="624"></figure><p><br></p><p data-pid="ee_TV49C">可以看出，V-Prior 与音频潜空间的对齐度显著更高（MSE 更低、CKA 更高），同时生成音质（FD）也更优。</p><p data-pid="k2TodgR1">这说明：<b>视频先验本身携带了更贴近音频的结构信息，能天然作为更合理的生成起点。</b></p><p data-pid="Adeyn2hT">团队进一步利用 t-SNE 将两种先验与目标音频潜空间进行可视化。</p><p><br></p><figure data-size="normal"><img class="origin_image zh-lightbox-thumb lazy" data-caption data-original="https://pic1.zhimg.com/v2-57c34fe27745da4b511c770d9b418b6f_720w.jpg?source=d16d100b" data-rawheight="378" data-rawwidth="574" data-size="normal" referrerpolicy="no-referrer" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-57c34fe27745da4b511c770d9b418b6f_720w.jpg?source=d16d100b" width="574"></figure><p><br></p><p data-pid="TPy2w1Ru">不同先验空间及生成过程可视化对比</p><p data-pid="82TYgrfb">结果显示：</p><ul><li data-pid="2arsPdXc"><b>高斯先验分布随机且离散，</b>其到音频空间的映射路径交叉密集；</li><li data-pid="xLNLPn1q"><b>视频先验分布则与音频潜空间结构更一致，</b>流动路径平滑，语义结构更清晰。</li></ul><p data-pid="JhRRxP_S">这说明视频先验在空间结构上更贴合目标模态，<b>能有效减少跨模态传输中的「弯路」，</b>实现更稳定、更高效的生成。</p><p data-pid="bqKMTafm"><b>性能对比：更快、更稳、更强、可规模化提升</b></p><p data-pid="xsIxNpxO"><b>Diffusion vs Flow vs VAFlow</b></p><p data-pid="dns0_j7_">作者在相同配置下（视觉特征、网络结构、初始化与超参数完全一致）对比了三种不同的生成范式以探究它们的性能差异。分别为：扩散模型（标准 DDPM）、主流流匹配模型（高斯噪声先验）以及 VAFlow（以视频特征为原始分布）。</p><p data-pid="t7x9MM8Y">结果表明：<b>两种流匹配模型在收敛速度与 FD 指标上均优于扩散模型，验证了流匹配在训练效率上的天然优势；而 VAFlow 虽在早期收敛略慢，但最终经过联合训练阶段取得了最低 FD。</b>这种提升得益于它直接建模了更具结构性的视频 - 音频传输路径，避免了高斯噪声先验下的模糊映射。</p><p><br></p><figure data-size="normal"><img class="origin_image zh-lightbox-thumb lazy" data-caption data-original="https://pic1.zhimg.com/v2-87b867d241923f72d4b5dc383709b89e_720w.jpg?source=d16d100b" data-rawheight="330" data-rawwidth="500" data-size="normal" referrerpolicy="no-referrer" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://picx.zhimg.com/v2-87b867d241923f72d4b5dc383709b89e_720w.jpg?source=d16d100b" width="500"></figure><p><br></p><p data-pid="NGiWjLQB"><b>Scaling Analysis</b></p><p data-pid="UMbOUNrb">本文作者发现，VAFlow 随模型规模增大仍保持持续性能提升，这意味着 <b>VAFlow 不仅在小模型上高效，参数量增加时同样稳定可拓展，</b>这为未来构建更强大的多模态生成模型奠定了基础。</p><p><br></p><figure data-size="normal"><img class="content_image lazy" data-caption data-rawheight="280" data-rawwidth="386" data-size="normal" referrerpolicy="no-referrer" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pica.zhimg.com/v2-f470e95b46b932ec963f0e334d241b25_720w.jpg?source=d16d100b" width="386"></figure><p><br></p><p data-pid="1AbXYUiN"><b>Benchmark 结果：超越现有 SOTA</b></p><p><br></p><figure data-size="normal"><img class="origin_image zh-lightbox-thumb lazy" data-caption data-original="https://picx.zhimg.com/v2-05f253348b1bfaba9c6a21e6f4562fe6_720w.jpg?source=d16d100b" data-rawheight="502" data-rawwidth="1060" data-size="normal" referrerpolicy="no-referrer" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-05f253348b1bfaba9c6a21e6f4562fe6_720w.jpg?source=d16d100b" width="1060"></figure><p><br></p><p data-pid="vc9sgqIZ">研究团队在 V2A 领域常用的数据集 VGGSound 上对 VAFlow 和其他基线模型进行了对比测试。</p><p data-pid="jbIOSHfx">实验结果显示，<b>VAFlow 在音频生成质量（Quality）相关指标上全面超越了现有 SOTA，获得了最佳分数。</b>尽管没有设计复杂的视频条件模块，在音视频的时序同步（Sync）和语义相关性（Semantic）方面，也达到了与 SOTA 相当的效果。</p><p data-pid="tMyiiGHk">值得一提的是，与经过文本 - 音频数据增强的 V2A 模型（表格中的灰色行）相比，VAFlow 在没有任何文本标注数据的前提下，语义相关性方面的表现仍能更优或相当。</p><p data-pid="6pTvJ9Yb"><b>真实效果</b></p><p><br></p><figure data-size="normal"><img class="origin_image zh-lightbox-thumb lazy" data-caption data-original="https://picx.zhimg.com/v2-b5a0629a6548eef885156b3601a71524_720w.jpg?source=d16d100b" data-rawheight="816" data-rawwidth="702" data-size="normal" referrerpolicy="no-referrer" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-b5a0629a6548eef885156b3601a71524_720w.jpg?source=d16d100b" width="702"></figure><p><br></p><p data-pid="As42u6l_">作者展示了一个沙滩场景视频的例子，该视频包括背景中的海浪声和来自不同角色的声音（人群的嘈杂声、女人说话）。可视化结果对比了真值和不同方法生成的音频的梅尔谱图。从图中可以观察到，VAFlow 不仅能精准理解复杂场景并生成所有必要的声音，而且还能与视觉时序保持同步。模型的其他生成结果可在主页试听。</p><p data-pid="Cnl5fqdL"><b>总结与展望</b></p><p data-pid="EwYxWYkm">VAFlow 为 V2A 开辟了一条从视频直接映射到音频的全新流匹配生成范式，也为构建通用跨模态生成基础模型提供了新思路。未来，团队将继续探索 VAFlow 在语音、音乐等更广泛音频领域的应用。</p>
</div>

<div>
<div class="tag-plugin link dis-select"><a class="link-card plain" title="重新定义跨模态生成的流匹配范式，VAFlow让视频「自己发声」" href="https://zhuanlan.zhihu.com/p/1967614134435681186" target="_blank" rel="external nofollow noopener noreferrer"><div class="left"><span class="title">重新定义跨模态生成的流匹配范式，VAFlow让视频「自己发声」</span><span class="desc fs12">https://zhuanlan.zhihu.com/p/1967614134435681186</span></div><div class="right"><div class="lazy img" data-bg="https://static.mhuig.top/gh/cdn-x/placeholder@1.0.1/link/8f277b4ee0ecd.svg"></div></div></a></div>
</div>



<div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/me-shaon/GLWTPL/blob/master/translations/LICENSE_zh-CN">GLWT（Good Luck With That，祝你好运）公共许可证</a> 许可协议。</p>
</div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="header cap theme"><span>接下来阅读</span></section><section class="body fs14"><a id="next" href="/rss/8fd20786.html">上传项目至GitHub与从Github克隆项目<span class="note">较早</span></a><div class="line"></div><a id="prev" href="/rss/e1808919.html">港科提出新算法革新大模型推理范式：随机策略估值竟成LLM数学推理「神操作」<span class="note">较新</span></a></section></div>


<div class="related-wrap reveal" id="related-posts">
    <section class="header">
      <div class="title cap theme">您可能感兴趣的文章</div>
    </section>
    <section class="body">
    <div class="related-posts"><a class="item" href="/rss/e533cfdd.html" title="「套壳」的最高境界：OpenAI揭秘Atlas浏览器架构OWL"><div class="img"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://picx.zhimg.com/v2-b14cd0fab50911f2501d5c15b0951aad_720w.jpg?source=d16d100b"></div><span class="title">「套壳」的最高境界：OpenAI揭秘Atlas浏览器架构OWL</span></a><a class="item" href="/rss/4ce5006b.html" title="一站看尽NeurIPS 2025前沿成果，11月22日北京见！"><div class="img"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-27329d9e86e297061af9abb979f64a94_1440w.jpg"></div><span class="title">一站看尽NeurIPS 2025前沿成果，11月22日北京见！</span></a><a class="item" href="/rss/87c0a85e.html" title="世界模型可单GPU秒级生成了？腾讯开源FlashWorld，效果惊艳、免费体验"><div class="img"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pica.zhimg.com/v2-b8803d9ec302a4a8077f238d25cc4b4c_1440w.jpg"></div><span class="title">世界模型可单GPU秒级生成了？腾讯开源FlashWorld，效果惊艳、免费体验</span></a><a class="item" href="/rss/881f08a3.html" title="AI版盗梦空间？Claude竟能察觉到自己被注入概念了"><div class="img"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pica.zhimg.com/v2-a24ab3f367283fd1b5f06854c1182198_1440w.jpg"></div><span class="title">AI版盗梦空间？Claude竟能察觉到自己被注入概念了</span></a><a class="item" href="/rss/ec2e4bc.html" title="人大、清华DeepAnalyze，让LLM化身数据科学家"><div class="img"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pica.zhimg.com/v2-b8803d9ec302a4a8077f238d25cc4b4c_1440w.jpg"></div><span class="title">人大、清华DeepAnalyze，让LLM化身数据科学家</span></a><a class="item" href="/rss/9620cacc.html" title="刚刚，智源悟界·Emu3.5登场，原生具备世界建模能力"><div class="img"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://picx.zhimg.com/v2-b7204d094a031d3683f4e994f200ee92.jpg?source=382ee89a"></div><span class="title">刚刚，智源悟界·Emu3.5登场，原生具备世界建模能力</span></a><a class="item" href="/rss/2a0de12e.html" title="单张4090跑到30fps，范浩强团队让VLA实时跑起来了"><div class="img"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-b8803d9ec302a4a8077f238d25cc4b4c_720w.jpg?source=d16d100b"></div><span class="title">单张4090跑到30fps，范浩强团队让VLA实时跑起来了</span></a><a class="item" href="/rss/e1808919.html" title="港科提出新算法革新大模型推理范式：随机策略估值竟成LLM数学推理「神操作」"><div class="img"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://picx.zhimg.com/v2-b8803d9ec302a4a8077f238d25cc4b4c_720w.jpg?source=d16d100b"></div><span class="title">港科提出新算法革新大模型推理范式：随机策略估值竟成LLM数学推理「神操作」</span></a><a class="item" href="/rss/5d56ae86.html" title="刚刚，Kimi开源新架构，开始押注线性注意力"><div class="img"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-363b9748f942d91888a414186797979a_1440w.jpg"></div><span class="title">刚刚，Kimi开源新架构，开始押注线性注意力</span></a><a class="item" href="/rss/ca5454bb.html" title="AI百科全书SciencePedia：当马斯克Grokipedia遭遇滑铁卢，有个中国团队默默把活儿干了"><div class="img"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://picx.zhimg.com/v2-90b8d9d2db6036666ec62b38dba81e0f_1440w.jpg"></div><span class="title">AI百科全书SciencePedia：当马斯克Grokipedia遭遇滑铁卢，有个中国团队默默把活儿干了</span></a><a class="item" href="/rss/4b347ad2.html" title="OpenAI首个GPT-5找Bug智能体：全自动读代码找漏洞写修复"><div class="img"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic2.zhimg.com/v2-c3d5a9680236638717542c097d62d427_1440w.jpg"></div><span class="title">OpenAI首个GPT-5找Bug智能体：全自动读代码找漏洞写修复</span></a><a class="item" href="/rss/e8e18acd.html" title="Sora连更三大新功能！一键打造IP形象，限时免注册码抢占安卓市场"><div class="img"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cors.mhuig.top/?r=https://zhuanlan.zhihu.com&url=https://pic1.zhimg.com/v2-227408c45b662a96d699e950c7d84d4a_720w.jpg?source=d16d100b"></div><span class="title">Sora连更三大新功能！一键打造IP形象，限时免注册码抢占安卓市场</span></a></div></section></div>





      
<footer class="page-footer reveal fs12"><hr><div class="sitemap"><div class="sitemap-group"><span class="fs14">RSS</span><a href="/">近期</a><a href="/categories/">分类</a><a href="/tags/">标签</a><a href="/archives/">归档</a></div><div class="sitemap-group"><span class="fs14">Support</span><a target="_blank" rel="noopener" href="https://blog.mhuig.top/">博客</a><a target="_blank" rel="noopener" href="https://api.mhuig.top/">API</a><a target="_blank" rel="noopener" href="https://ssl.mhuig.top/">SSL Status</a><a target="_blank" rel="external nofollow noopener noreferrer" href="https://mhuig.instatus.com/">Status Monitors</a></div><div class="sitemap-group"><span class="fs14">社交</span><a target="_blank" rel="noopener" href="https://blog.mhuig.top/pages/friends/">友链</a><a target="_blank" rel="noopener" href="https://blog.mhuig.top/pages/about/">留言板</a></div><div class="sitemap-group"><span class="fs14">更多</span><a target="_blank" rel="noopener" href="https://mhuig.top/">关于我</a><a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/MHuiG">GitHub</a><a href="/contact/">Contact</a><a href="/privacy-policy/">隐私政策</a></div></div><div class="text"><p>本站由 <a target="_blank" rel="noopener" href="https://mhuig.top/">MHuiG</a> 使用 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/xaoxuu/hexo-theme-stellar">Stellar</a> 主题创建，您可以在 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/MHG-LAB/RSSBOX">GitHub</a> 找到本站源码<br>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/me-shaon/GLWTPL/blob/master/translations/LICENSE_zh-CN">GLWT（Good Luck With That，祝你好运）公共许可证</a> 许可协议，转载请注明出处。</p>
</div></footer>

      <div class="float-panel mobile-only blur" style="display:none">
  <button type="button" class="sidebar-toggle mobile" onclick="sidebar.toggle()">
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewbox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"/><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"/></svg>
  </button>
</div>

    </div>
  </div>
  <div class="scripts">
    <script type="text/javascript">
  stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.9.0';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://static.mhuig.top/npm/jquery@3.5.1/dist/jquery.min.js',
    sitesjs: '/js/plugins/sites.js',
    friendsjs: '/js/plugins/friends.js',
  };

  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://static.mhuig.top/npm/vanilla-lazyload@17.3.1/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@6/swiper-bundle.min.css","js":"https://unpkg.com/swiper@6/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://static.mhuig.top/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://static.mhuig.top/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://static.mhuig.top/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://static.mhuig.top/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://static.mhuig.top/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img,article.content img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti/umd/heti.min.css","js":"https://unpkg.com/heti/umd/heti-addon.min.js"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->



<!-- inject -->


  </div>
</body>
</html>
